---
layout: post
title:      "Scraping Information"
date:       2020-10-26 02:24:38 +0000
permalink:  scraping_information
---


I've been building an API recently and have been using Nokogiri to scrape the information that will be stored in my Ruby database. However, it has been an enormous pain just getting it to work properly with the site that I have been scraping from. While it is extremely useful and saves a ton of effort once instituted the process of setting it up makes me wonder at if it is actually worth the effort! Once I realized that I was using the wrong selectors the whole process became much easier. How much time could be saved if we could do this in normal life too? Cut out only the information that we need in neat little chunks to be output for use as we please? I suppose the use of Google and finding every thing that we search for is a similar thought as we can find anything that we need to know. But as technology advaces so do we and I can't wait to see what the next Nokogiri or Google is
